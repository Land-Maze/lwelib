\chapter{Theoretical Background}
\label{ch:theoretical_background}

This chapter establishes the mathematical and computational foundations necessary for this thesis.
We begin by defining the complexity classes that underpin modern cryptography, analyze the specific threats posed by quantum computing, and finally detail the lattice-based structures and algorithms-specifically Module-LWE and the Number Theoretic Transform that gives secure and efficient post-quantum communication.

\section{Cryptography and Computational Hardness: P vs NP Problem}
\label{sec:cryptography_fundamentals}

The primary objective of modern cryptography is to ensure confidentiality, integrity, and authenticity (the CIA triad) in the presence of adversaries.
Public-key cryptography (PKC) relies on mathematical functions that are easy to compute in one direction but computationally infeasible to invert without a specific private key.

To understand "infeasibility," we must define the underlying computational complexity classes.
The P vs NP problem is a major unsolved question in theoretical computer science that asks whether every problem whose solution can be quickly verified can also be quickly solved~\cite{millennium_p_vs_np}.
This distinction is fundamental to the existence of modern cryptography.

\begin{itemize}
    \item \textbf{Class P (Polynomial Time):} Problems that can be solved by a classical computer in a number of steps defined by a polynomial function of the input size $n$ (e.g., $O(n^2)$). These are considered "easy" or tractable.
    \item \textbf{Class NP (Nondeterministic Polynomial Time):} Problems where a provided solution can be \textit{verified} in polynomial time.
    \item \textbf{NP-Hard and NP-Complete:} The \textit{hardest} problems in NP. If an efficient solution were found for an NP-complete problem, it would imply that P = NP, rendering most current cryptography insecure~\cite{wiki_p_vs_np}.
\end{itemize}

Cryptography relies on the assumption of \textbf{One-Way Functions (OWF)}: functions that are in P (easy to compute) but require NP-hard effort to invert.
If P were to equal NP, a computer could efficiently find a secret key $sk$ from a public key $pk$, effectively making all cryptography impossible.
\section{The Quantum Threat}
\label{sec:quantum_threat}

While classical cryptography relies on the assumption that Integer Factorization and Discrete Logarithms are hard, this assumption does not hold against quantum adversaries.
Quantum computing introduces a new paradigm of computation utilizing the principles of superposition and entanglement.

\subsection{Quantum Computing Fundamentals}
\label{subsec:quantum_computing_basics}

Unlike classical computers that operate on bits (0 or 1), quantum computers operate on qubits.
A qubit is a unit of quantum information that exists as a probabilistic combination of basis states, denoted as $|0\rangle$ and $|1\rangle$.

\[ |\psi\rangle = \alpha|0\rangle + \beta|1\rangle \]
where $\alpha$ and $\beta$ are complex numbers satisfying the normalization condition $|\alpha|^2 + |\beta|^2 = 1$.

\subsubsection{Interference and Computation}
It is a common misconception that quantum computers simply "try all possible solutions at once".
Instead, they rely on \textit{quantum interference}.
Quantum algorithms use sequences of unitary gates (like Hadamard or CNOT) to manipulate the probability amplitudes $\alpha$ and $\beta$.
The goal is to cause the amplitudes of incorrect solutions to interfere destructively (cancel out) while the amplitudes of the correct solution interfere constructively.
This allows the system to collapse into the correct state upon measurement with high probability.

\subsubsection{The Bloch Sphere Representation}

On the Bloch sphere (Figure~\ref{fig:bloch_sphere_visualisation}), any qubit state can be represented as a point on the surface of a unit sphere.
The North and South poles represent the basis states $|0\rangle$ and $|1\rangle$, respectively, while any other point corresponds to a superposition of these states.
The state vector's position is defined by the polar angle $\theta$ and the azimuthal angle $\varphi$, resulting in the following representation:

\[ |\psi\rangle = \cos\left(\frac{\theta}{2}\right)|0\rangle + e^{i\varphi}\sin\left(\frac{\theta}{2}\right)|1\rangle \]

\begin{figure}[htbp]
    \centering
    \includesvg[width=0.3\textwidth]{bloch_sphere.svg}
    \caption{Bloch Sphere Visualisation. \newline\centering[Source: "Bloch sphere". Wikipedia. https://en.wikipedia.org/wiki/Bloch\_sphere.
    12.11.2025]}
    \label{fig:bloch_sphere_visualisation}
\end{figure}

\subsection{Algorithmic Vulnerabilities}
\label{subsec:shor_and_grover}

Two primary quantum algorithms necessitate the transition to Post-Quantum Cryptography (PQC):

\subsubsection{Shor's Algorithm}
Peter Shor introduced an algorithm that solves Integer Factorization and Discrete Logarithm problems in polynomial time.
For an RSA key of length $n$, classical sieving requires sub-exponential time, whereas Shor's algorithm requires only $O(n^2 (\log n) (\log \log n))$ gates.
This effectively breaks RSA and Elliptic Curve Cryptography (ECC).

\subsubsection{Grover's Algorithm}
Grover's algorithm provides a quadratic speedup for searching unsorted databases.
While less catastrophic than Shor's algorithm, it implies that symmetric primitives (like AES) and hash functions (like SHA-3) must double their key sizes to maintain equivalent security levels.


\subsubsection{Implications for Cryptography}

Both algorithms suffer from significant implementation challenges, such as: qubit coherence times (the duration qubits maintain their quantum state); High gate error rates.
Breaking commonly used key sizes requires millions of physical qubits to account for quantum error correction, making such attacks currently impractical.

The record for the largest integer factored by a quantum computer remains 21, achieved in 2012 by \textlatin{Lucero et al.} using a superconducting quantum processor~\cite{Lucero2012-pp}.
This highlights the vast disparity between current experimental capabilities and the scales required to threaten modern cryptographic standards.

\section{Lattice-Based Cryptography}
\label{sec:lattice_based_cryptography}

In response to the quantum threat, the National Institute of Standards and Technology (NIST) has standardized Lattice-based cryptography.
Lattices are resistant to both Shor's and Grover's algorithms because their underlying mathematical problems are believed to be hard even for quantum computers.

\subsection{Lattice Definition}
\label{subsec:lattice-definition}
A lattice $\mathcal{L}$ is a discrete subgroup of $\mathbb{R}^n$.
It is defined as the set of all integer linear combinations of linearly independent basis vectors $\mathbf{b}_1, \dots, \mathbf{b}_k \in \mathbb{R}^n$:
\[ \mathcal{L}(\mathbf{B}) = \left\{ \sum_{i=1}^k z_i \mathbf{b}_i : z_i \in \mathbb{Z} \right\} \]
The security of lattice schemes stems from geometric problems such as the \textbf{Shortest Vector Problem (SVP)} and the \textbf{Closest Vector Problem (CVP)}.
In their exact forms, these problems are proven to be NP-hard.

In Figure~\ref{fig:lattice_visualisation}, the vectors $\mathbf{b}_1$ and $\mathbf{b}_2$ form the basis.
Vector $\mathbf{s}$ represents a solution to the SVP, while finding the lattice point $\mathbf{z}$ closest to target $\mathbf{t}$ represents the CVP\@.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{lattice}
    \caption{Visualisation of a 2D Lattice. \newline\centering[Source: "What is Lattice-based Cryptography?". Utimaco. https://utimaco.com/service/knowledge-base/post-quantum-cryptography/what-lattice-based-cryptography]}
    \label{fig:lattice_visualisation}
\end{figure}

\subsubsection{Shortest Vector Problem (SVP)}
The SVP asks to find the shortest non-zero vector in a lattice.
Given a basis $\mathbf{B}$, the goal is to find a vector $\mathbf{v} \in \mathcal{L}(\mathbf{B})$ such that:
\[\|\mathbf{v}\| = \lambda_1(\mathcal{L}) = \min_{\mathbf{u} \in \mathcal{L}(\mathbf{B}) \setminus \{\mathbf{0}\}} \|\mathbf{u}\| \]

In Figure~\ref{fig:lattice_visualisation}, vector $\mathbf{s}$ (green) illustrates this concept.
In basic terms, this means finding the smallest "step" possible that lands exactly on a non-zero lattice point.

\subsubsection{Closest Vector Problem (CVP)}
The CVP asks to find the lattice vector closest to an arbitrary target vector $\mathbf{t} \in \mathbb{R}^n$.
Formally, given a basis $\mathbf{B}$ and a target $\mathbf{t}$, the goal is to find $\mathbf{v} \in \mathcal{L}(\mathbf{B})$ such that:
\[\|\mathbf{t} - \mathbf{v}\| = \min_{\mathbf{u} \in \mathcal{L}(\mathbf{B})} \|\mathbf{t} - \mathbf{u}\| \]

As shown in Figure~\ref{fig:lattice_visualisation}, this involves identifying the point $\mathbf{z}$ (green dot) that is nearest to the target point $\mathbf{t}$ (pink dot).

\subsection{Learning With Errors (LWE)}
\label{subsec:lwe}

The Learning With Errors (LWE) problem is essentially the cryptographic realization of the Closest Vector Problem (CVP).
It requires recovering a secret vector $\mathbf{s} \in \mathbb{Z}_q^n$ from a system of noisy linear equations:
\[ A\mathbf{s} + \mathbf{e} = \mathbf{b} \pmod q \]
where $A$ is a uniform matrix and $\mathbf{e}$ is a small error vector drawn from an error distribution $\chi$.

\begin{figure}[htbp]
    \centering
    \begin{tabular}{ccccc}
        $\mathbf{A}$ & $\times$ & $\mathbf{s}$ & $+$ & $\mathbf{e}$ \\
        $\left[ \begin{array}{ccc}
                    \cdot & \cdot & \cdot \\
                    \cdot & \text{random} & \cdot \\
                    \cdot & \cdot & \cdot
        \end{array} \right]$ &
        $\times$ &
        $\left[ \begin{array}{c}
                    \cdot \\ \text{secret} \\ \cdot
        \end{array} \right]$ &
        $+$ &
        $\left[ \begin{array}{c}
                    \cdot \\ \text{noise} \\ \cdot
        \end{array} \right]$ \\
        $m \times n$ & & $n \times 1$ & & $m \times 1$
    \end{tabular}
    \caption{Structural definition of the LWE problem. The public matrix $A$ has dimensions $m \times n$, the secret vector $\mathbf{s}$ has dimension $n$, and the noise $\mathbf{e}$ is a vector of dimension $m$. \newline\centering[Source: Own work].}
    \label{fig:lwe_definition_matrix}
\end{figure}

Standard LWE is secure but inefficient because the public matrix $A$ requires $O(n^2)$ storage, leading to kilobyte-sized keys that are impractical for many real-world applications~\cite{Lindner2011-wg}.

\begin{figure}[htbp]
    \centering
    \[
        \begin{bmatrix}
            4 & 1 & 11 & 10 \\
            5 & 5 & 9 & 5 \\
            3 & 9 & 0 & 10 \\
            1 & 3 & 3 & 2 \\
            12 & 7 & 3 & 4 \\
            6 & 5 & 11 & 4 \\
            3 & 3 & 5 & 0
        \end{bmatrix}
        \times
        \begin{bmatrix}
            6 \\ 9 \\ 11 \\ 11
        \end{bmatrix}
        +
        \begin{bmatrix}
            0 \\ -1 \\ 1 \\ 1 \\ 1 \\ 0 \\ -1
        \end{bmatrix}
        =
        \begin{bmatrix}
            4 \\ 7 \\ 2 \\ 11 \\ 5 \\ 12 \\ 8
        \end{bmatrix}
    \]
    \caption{Numerical example of LWE operations with $n=4, m=7, q=13$. The matrix $A \in \mathbb{Z}_{13}^{7 \times 4}$ is multiplied by secret $\mathbf{s} \in \mathbb{Z}_{13}^{4 \times 1}$, and noise $\mathbf{e} \in \mathbb{Z}_{13}^{7 \times 1}$ is added to produce $\mathbf{b} \in \mathbb{Z}_{13}^{7 \times 1}$. All operations are performed modulo 13. \newline\centering[Source: Own work].}
    \label{fig:lwe_operations_matrix}
\end{figure}



As shown in Figure~\ref{fig:lwe_operations_matrix}, each row of the result $\mathbf{b}$ is a linear combination of the secret $\mathbf{s}$ and a row of $A$, slightly perturbed by the noise $\mathbf{e}$.
This noise prevents an adversary from using Gaussian elimination to recover the secret~\cite{Fauzi2021-gw}.

\section{Module-LWE and Algebraic Structures}
\label{sec:m_lwe_structures}

To achieve the "Fast Implementation" goal of this thesis, we utilize Module-LWE (M-LWE). M-LWE balances the high security of standard LWE with the efficiency of structured variants like Ring-LWE\@.

The key innovation in M-LWE is the use of polynomial rings instead of integers.
Specifically, we work over the ring $R_q = \mathbb{Z}_q[X] / \langle X^d + 1 \rangle$, where $d$ is typically 256 (same as in CRYSTALS-Kyber~\cite[page 4]{kyber_spec_2021}).
In this setting, the elements of the matrix $A$ and the vectors $\mathbf{s}, \mathbf{e}$ are polynomials rather than individual integers.

This structured approach allows a single polynomial to represent many linear relations.
Consequently, M-LWE significantly reduces the size of public keys from $O(n^2)$ to $O(k^2 d)$, where $k$ is the rank of the module.
This reduction in storage and the resulting speed increase in arithmetic operations make M-LWE, as used in CRYSTALS-Kyber, an ideal candidate for high-performance post-quantum cryptography.

\subsection{The Ring Structure}
\label{subsec:the-ring-structure}
We operate over the ring $R_q = \mathbb{Z}_q[X] / \langle X^d + 1 \rangle$, where $d=256$ is a power of 2.
In this setting, elements are not single numbers but polynomials of degree $d-1$.
This structure allows us to represent the public matrix $A$ in a compressed form, significantly reducing memory usage from kilobyte-sized keys to compact polynomial representations.

\subsubsection{Polynomial Representation}
Each element in $R_q$ is represented as a polynomial:
\[ f(X) = a_0 + a_1 X + a_2 X^2 + \dots + a_{d-1} X^{d-1} \]
where $a_i \in \mathbb{Z}_q$.
Polynomial addition and multiplication are performed modulo $X^d + 1$ and $q$.

Additionally, the matrix-vector multiplication in M-LWE involves polynomial multiplications, which can be optimized using the Number Theoretic Transform (NTT), as discussed in Section~\ref{sec:ntt}.

\subsection{Module-LWE Definition}
\label{subsec:module-lwe-definition}
In M-LWE, the secret $\mathbf{s}$ is a vector (module) of rank $k$ over the ring $R_q$.
The defining equation becomes:
\[ \mathbf{b} = A\mathbf{s} + \mathbf{e} \in R_q^k \]
where matrix multiplication involves polynomial multiplication.
The parameter $k$ allows us to tune security: Kyber-512 uses $k=2$, while Kyber-768 uses $k=3$.
With increased $k$, the security level rises, but so does computational complexity.

\section{The Number Theoretic Transform (NTT)}
\label{sec:ntt}

The Number Theoretic Transform (NTT) is the critical algorithmic driver for high-performance M-LWE implementations.
It is a generalization of the Fast Fourier Transform (FFT) adapted for finite fields.

\subsection{The Multiplication Bottleneck}
\label{subsec:the-multiplication-bottleneck}
The primary performance bottleneck in M-LWE is computing the product of polynomials in $R_q$.
Using standard "schoolbook" multiplication, this requires $O(d^2)$ operations.
For $d=256$, this results in $65,536$ operations per multiplication, which is prohibitively slow for real-time applications.

\subsection{NTT optimization}
\label{subsec:ntt-optimization}
The NTT reduces this complexity to $O(d \log d)$.
\begin{equation}
    \label{eq:ntt_multiplication}
    Y(x) = f(x) \cdot g(x) = \text{INTT}(\text{NTT}(f) \circ \text{NTT}(g))
\end{equation}
By transforming polynomials into the NTT domain using a primitive $2d$-th root of unity $\zeta$, multiplication becomes a simple point-wise operation (denoted by $\circ$ in Equation~\ref{eq:ntt_multiplication}).
This thesis focuses on the \textbf{Negacyclic NTT}, which avoids zero-padding by working directly in the ring $\mathbb{Z}_q[X] / \langle X^d + 1 \rangle$.

\subsubsection{Negacyclic NTT}
\label{subsubsec:negacyclic_ntt}

For rings of the form $R_q = \mathbb{Z}_q[X] / \langle X^d + 1 \rangle$, the standard cyclic NTT is not directly applicable without padding~\cite{guide_to_ntt}.
Instead, we utilize the \textbf{negacyclic NTT}, also known as the negative wrapped convolution.
As defined in Equation~\ref{eq:nwc}, the negacyclic convolution $NWC(x)$ of two polynomials $G(x)$ and $H(x)$ is their product reduced modulo $X^d + 1$:

\begin{equation}
    \label{eq:nwc}
    NWC(x) = Y(x) \pmod{X^d + 1}
\end{equation}

By utilizing this specialized transform, we can perform the polynomial multiplication bottleneck in $O(d \log d)$ time without doubling the length of the input vectors through zero-padding.
This is achieved by using a primitive $2d$-th root of unity $\zeta$ to evaluate the polynomials at the roots of the cyclotomic polynomial $\Phi_{2d}(X) = X^d + 1$.

\begin{figure}[htbp]
    \centering
    \[
        \hat{\mathbf{f}} =
        \begin{bmatrix}
            1 & \zeta^1 & \zeta^2 & \dots & \zeta^{d-1} \\
            1 & \zeta^3 & \zeta^6 & \dots & \zeta^{3(d-1)} \\
            \vdots & \vdots & \vdots & \ddots & \vdots \\
            1 & \zeta^{2d-1} & \zeta^{2(2d-1)} & \dots & \zeta^{(d-1)(2d-1)}
        \end{bmatrix}
        \begin{bmatrix}
            f_0 \\ f_1 \\ f_2 \\ \vdots \\ f_{d-1}
        \end{bmatrix} \pmod q
    \]
    \caption{Matrix-vector representation of the Negacyclic NTT evaluation. The coefficient vector $\mathbf{f}$ is transformed into the NTT domain $\hat{\mathbf{f}}$ by evaluation at odd powers of the $2d$-th primitive root of unity $\zeta$.}
    \label{fig:negacyclic_ntt_matrix}
\end{figure}


While schoolbook methods for negatively wrapped modular multiplication have $O(d^2)$ complexity, the negacyclic NTT allows for highly efficient, in-place implementations that are essential for the high-performance requirements of this thesis.
Once transformed, the multiplication of two polynomials $f$ and $g$ is simplified to a point-wise (Hadamard) product in the NTT domain:

\begin{equation}
    \label{eq:ntt_convolution}
    \text{NTT}(f \cdot g) = \text{NTT}(f) \circ \text{NTT}(g)
\end{equation}

\section{Summary}
\label{sec:summary_chapter_1}

This chapter established the theoretical framework for the thesis.
We reviewed the computational hardness assumptions that underpin modern cryptography and analyzed why the P vs NP problem is central to security.
We identified the existential threat posed by quantum algorithms, specifically Shor's and Grover's, and presented Lattice-based cryptography as the robust solution.
We detailed the transition from standard LWE to Module-LWE, highlighting how the algebraic structure of polynomial rings offers superior efficiency.
Finally, we introduced the Number Theoretic Transform (NTT) as the essential mathematical tool for optimizing these schemes.
The following chapters will build upon these foundations to design, implement, and benchmark a high-speed M-LWE cryptographic library.